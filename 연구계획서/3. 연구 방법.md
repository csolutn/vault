### **3.1. 데이터 수집**

**사용자 인터페이스 : 자체개발 온라인 저지 플랫폼 – [Codelog.site]**

- **Code Editor**: 사용자가 실시간으로 코드를 작성할 수 있는 웹 기반 에디터
- **Code Runner**: 작성된 코드를 서버에서 실행하고 결과를 반환
- **자동 채점 시스템**: 미리 정의된 테스트 케이스를 기반으로 채점 결과 출력

**데이터 기록 방법**

- **기록 형식**: JSON (index, timestamp, time interval, content)
- **기록 조건**: 사용자의 키보드 입력, 붙여넣기, 실행, 제출(채점 결과) 등 이벤트 발생 시 자동 기록
- **저장소**: MongoDB 기반 로그 저장 시스템

**데이터 구성**

- **분석 대상**: 자료구조 과목의 학습 과제로부터 수집된 총 2063개의 응답 중 유효 응답 1764개를 분석 대상으로 삼음
- **응답자 특성**: 컴퓨터 비전공 교사 32명
- **제외 조건**: 채점 결과가 오답이거나 Null 응답, 로직을 포함하지 않거나 기존 코드의 재사용 만으로 해결 가능한 단순한 과제
    

---

### **3.2. 데이터셋 구축**

**라벨링**

- Codelog.site는 코드 편집 과정을 시각적으로 재생할 수 있는 기능을 제공함
- 이를 통해 연구자가 직접 **프로그래밍 과정 중 복사/붙여넣기 행위의 질적 특성**을 분석하여 붙여넣기를 통한 도용 여부에 대한 라벨링 수행
- 라벨링 세부 기준 : 1. 기존에 존재했던 내용 2. 로직 포함여부 3. 로직 수정여부
  
**전처리**
- JSON 로그를 기반으로 불필요한 이벤트 제거 (예: 빈 입력, 비반응 클릭 등)
- placeholder 제거 / 로그 보강 / 5자 이상 증가시 v로그 추가

**속성화 (Feature Engineering)**
- 라벨링 분기 시 사용된 특징을 모두 구조화된 속성으로 추출
- 주요 속성 : Typed ^ Submitted / Pasted(wo modified) ^ Submitted / 각 복사 붙여넣기에 대해 

---

### **3.3. 분류모델 개발**

**휴리스틱 모델**

- 사람이 정의한 기준 바탕으로 이진 분류
- 해석 용이성 및 베이스라인 모델로서의 역할 수행

**머신러닝 모델**

- `Random Forest`, `Logistic Regression`, `SVM`, `MLP` 등을 적용
- 입력: 전처리된 수치형 속성 벡터 / 출력: 라벨 (이진 또는 다중)
- 교차 검증 기반으로 성능 비교
- 최종 예측 확률 또는 중요 피처 시각화를 통해 해석 가능성 확보

---

### **3.4. 성능 평가**

**정확도 (Accuracy 및 F1 Score)**
- 휴리스틱 모델과 머신러닝 모델 간 성능 비교
- 주요 지표: Accuracy, Precision, Recall, F1 Score
**외적 타당도**
- 실제 시험 성적, 과제 평균, 코딩 경험 등 외부 평가 변수와의 상관성 분석
- 모델의 분류 결과가 현실적 능력 지표(예: 프로그래밍 실력, 문제해결 역량)와 일관되게 대응하는지 확인