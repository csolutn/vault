### **3.1. 데이터 수집**

**사용자 인터페이스 : 자체개발 온라인 저지 플랫폼 – [Codelog.site]**

본 연구는 연구자가 직접 개발한 온라인 저지 플랫폼 `Codelog.site`를 통해 데이터를 수집하였다. 해당 플랫폼은 다음과 같은 주요 기능을 제공한다:

- **Code Editor**: 사용자가 실시간으로 코드를 작성할 수 있는 웹 기반 에디터
    
- **Code Runner**: 작성된 코드를 서버에서 실행하고 결과를 반환
    
- **자동 채점 시스템**: 미리 정의된 테스트 케이스를 기반으로 제출된 코드의 정답 여부를 자동 판정 및 결과 제공
    

**데이터 기록 방법**

- **기록 형식**: JSON (index, timestamp, time interval, content)
    
- **기록 조건**: 사용자의 키보드 입력, 붙여넣기, 실행, 제출(채점 결과) 등 이벤트 발생 시 자동 기록
    
- **저장소**: MongoDB 기반 로그 저장 시스템
    

**데이터 구성**

- **분석 대상**: 자료구조 과목의 학습 과제로부터 수집된 총 2063개의 응답 중 유효 응답 1764개를 분석 대상으로 삼음
    
- **응답자 특성**: 컴퓨터 비전공 교사 32명
    
- **제외 조건**: 채점 결과가 오답이거나 Null 응답, 명백한 비정상 로그(입력 누락, 시간 왜곡 등)
    

---

### **3.2. 데이터셋 구축**

**라벨링**

- Codelog.site는 코드 편집 과정을 시각적으로 재생할 수 있는 기능을 제공함
    
- 이를 통해 연구자가 직접 **프로그래밍 과정의 질적 특성**(예: 복사/붙여넣기 여부, 문제해결 전략의 일관성 등)을 분석하여 라벨링 수행
    
- 일부 라벨은 자동 규칙(예: 붙여넣기 비율 60% 이상)으로 이진 분류 기준을 구성
    

**전처리**

- JSON 로그를 기반으로 불필요한 이벤트 제거 (예: 빈 입력, 비반응 클릭 등)
    
- 로그 간 시간 간격 정규화, 코딩 시작/종료 시간 동기화 처리
    

**속성화 (Feature Engineering)**

- 라벨링 분기 시 사용된 특징을 모두 구조화된 속성으로 추출
    
- 예: `붙여넣기 비율`, `타이핑 시간 분산`, `출력 시도 횟수`, `논리 키워드 비율`, `에러 수정 패턴` 등
    
- 향후 분류 모델 훈련에 직접 사용 가능한 수치적 또는 범주형 피처로 변환
    

---

### **3.3. 분류모델 개발**

**휴리스틱 모델**

- 사람이 정의한 기준(예: 붙여넣기 비율 > 0.6 and 타이핑 시간 분산 < 300ms)을 바탕으로 점수화하여 분류
    
- 각 속성에 대해 점수를 부여하고, 총점이 기준값을 넘는 경우 특정 라벨로 판단
    
- 해석 용이성 및 베이스라인 모델로서의 역할 수행
    

**머신러닝 모델**

- `Random Forest`, `Logistic Regression`, `SVM`, `MLP` 등을 적용
    
- 입력: 전처리된 수치형 속성 벡터 / 출력: 라벨 (이진 또는 다중)
    
- 교차 검증 기반으로 성능 비교
    
- 최종 예측 확률 또는 중요 피처 시각화를 통해 해석 가능성 확보
    

---

### **3.4. 성능 평가**

**정확도 (Accuracy 및 F1 Score)**

- 휴리스틱 모델과 머신러닝 모델 간 성능 비교
    
- 주요 지표: Accuracy, Precision, Recall, F1 Score
    

**외적 타당도**

- 실제 시험 성적, 과제 평균, 코딩 경험 등 외부 평가 변수와의 상관성 분석
    
- 모델의 분류 결과가 현실적 능력 지표(예: 프로그래밍 실력, 문제해결 역량)와 일관되게 대응하는지 확인